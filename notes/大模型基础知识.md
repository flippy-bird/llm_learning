## 大模型

### 分词

> [LLM实践系列-详谈Tokenizer训练细节](https://developer.volcengine.com/articles/7428432944974266418)
>
> [关于 tokenizer.json 词汇表中没有中文的问题](https://github.com/jingyaogong/minimind/issues/111)



<img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250923111829735.png" alt="image-20250923111829735" style="zoom:67%;" />

然后再embedding

<img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250923111856766.png" alt="image-20250923111856766" style="zoom: 40%;" /><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250923112548179.png" alt="image-20250923112548179" style="zoom: 100%;" />

#### MHA

一般大模型是使用下面这种更高效的实现

<img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250925110210536.png" alt="image-20250925110210536" style="zoom:50%;" />





#### BPE

BPE是目前大模型主流的两种分词之一，训练过程总结成一句话就是：迭代合并当前最高频的token对，直到到达预设词表大小上限。



#### BBPE

BBPE和BPE大体上是一样的，区别在于BPE把文本看作字符集合，第一步是按照字符切分获得初始token，BBPE把文本看作是二进制编码，按照8bit切分获得原始token。

```python
对于同一个句子：海水潮潮潮潮潮潮落,浮云长长长长长长长消

## BPE
 这句话首先会按字拆分成：海 水 潮 潮 潮 潮 潮 潮 落 , 浮 云 长 长 长 长 长 长 长 消
    
## BPPE
"\xe6\xb5\xb7\xe6\xb0\xb4\xe6\xbd\xae\xe6\xbd\xae\xe6\xbd\xae\xe6\xbd\xae\xe6\xbd\xae\xe6\xbd\xae\xe8\x90\xbd\x2c..."

然后取每一个2位16进制数作为初始token，也就是「\xe6」「\xb5」「\xb7」
	我们知道utf8是变长编码，ascii字符在utf8中的编码长度是1，也就是刚好一个2位16进制数。比如我上面句子里的逗号对应的utf8编码是“\x2c”。所以ascii字符一定会作为一个基础字符加入词表，而且也不会被拆分，所以英文单词、数字这种ascii字符组成的词，一定是整数个token表示的。但是汉字的编码长度大部分是3，比如“海”的编码是“\xe6\xb5\xb7”，这就导致汉字在bbpe的词表中并不一定是1个、2个字这种整数个token组成。可能是3/2个token表示一个汉字。

```

有个问题：基于BPPE的话，“\xe6\xb5\xb7” 这个解码应该怎么解码呢？不会变成 “\xe6", "\xb5","\xb7”吗？



### 细节部分

#### softmax的数值精度

![image-20250924120139209](https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250924120139209.png)

当Zi特别大或者特别小时，经过指数运算，如e^1000或者e^(-1000)时，会远超浮点数能够表示的范围，造成上溢或者下溢；

一个经典的做法是：在计算时减去最大值max(z):

![image-20250924120534724](https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250924120534724.png)

### SFT

> [SFT-22条经验](https://zhuanlan.zhihu.com/p/49398269658)
>
> [初学者如何对大模型进行微调？](https://www.zhihu.com/question/638803488/answer/1932858159267021495)
>
> [LLM-SFT-trick](https://zhuanlan.zhihu.com/p/682604566)
>
> [大模型SFT数据配比的一些实践启示](https://zhuanlan.zhihu.com/p/1944002824263407495)

这里SFT是指全量微调，lora等成为PEFT(搞笑参数微调)

#### 训练的库

有两种常用的方式，一种是：transformers中的TrainingArguments和Trainer, 另外一种是TRL库中的SFTtrainer。本质上，**TRL Trainer 是在 transformers 的 Trainer 基础上的扩展和包装**，旨在支持更复杂、高级的训练流程。

#### 微调数据格式

广泛使用的两种微调数据格式为Alpaca（Json结构）和share GPT,前者使用较多，后者更加关注长对话。



### VLA

> https://zhuanlan.zhihu.com/p/1949425599526446643

貌似在智能驾驶方面经常能听到VLA这个词，比如理想的VLA，小鹏的VLA，世界模型等等；

VLA(**Vision-Language-Action，视觉-语言-动作模型)** 是一种结合 **视觉输入**（如图像、视频）、**语言指令**（如自然语言命令）和 **动作输出**（如机器人控制信号、自动驾驶决策）的模型，实现“感知-理解-执行”的一体化的端到端大模型技术。

![image-20250912153358207](https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250912153358207.png)

下面是一个简单的VLA模型示例。其输入为图片，Prompt指令及点云数据，其输出为机械臂抓取的Action[x, y, z, roll, pitch, yaw, gripper_open]，即机械臂末端的坐标，角度，执行器状态等

```python
import torch
from transformers import AutoModelForVLATasks

# 加载预训练模型（例如端到端机器人控制模型）
model = AutoModelForVLATasks.from_pretrained("PointVLA/PointVLA-Robotics-v2")

# 输入数据准备
rgb_image = torch.randn(1, 3, 224, 224)  # RGB图像张量
point_cloud = torch.randn(1, 1024, 3)    # 点云数据（B, N, 3）
text_instruction = ["Pick up the red block"]  # 文本指令

# 调用模型生成动作
with torch.no_grad():
    actions = model.generate(
        images=rgb_image,
        point_clouds=point_cloud,
        text_inputs=text_instruction
    )

# 输出解析（示例：末端执行器位姿+夹爪状态）
# 格式: [x, y, z, roll, pitch, yaw, gripper_open]
print("预测动作:", action)  # 如 "[0.12, -0.45, 0.33, 0.1, 0.0, 1.57, 1]"
```

如果是自动驾驶的输出，格式则如下：

```python
    # 一个最简单的自动驾驶模型推理结果
    model_output = {
        "steering": 0.15,   # 轻微右转
        "throttle": 0.35,   # 适度加速
        "brake": 0.0,       # 不制动
        "gear": 1           # 前进档
    }
    
    # 转换为车辆控制指令
    vehicle_commands = {
        "转向角度": "2.7度",      # steering * 18度
        "油门开度": "35%",        # throttle * 100%
        "制动压力": "0%",         # brake * 100%
        "档位": "D档"            # 前进档
    }
```

具体的项目可以参考引用的链接





### 参考资料

1. 介绍LLM发展的：[万字长文，梳理从Deepseek、LLama、Gemma、Kimi等8种LLM结构设计](https://zhuanlan.zhihu.com/p/1935335369815094111)
2. 经验 + 基础知识的：[理了一些LLM应用方向的线索](https://zhuanlan.zhihu.com/p/1889768317293674846)



